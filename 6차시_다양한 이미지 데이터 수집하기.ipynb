{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 이미지 데이터 수집하기\n",
    "# 필요한 모듈과 라이브러리를 로딩하고 검색어를 입력 받습니다\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver as wd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import urllib.request\n",
    "import urllib\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#사용자에게 필요한 정보들을를 입력 받습니다.\n",
    "print(\"=\" *80)\n",
    "print(\" 이 크롤러는 이미지 정보를 수집합니다\")\n",
    "print(\"=\" *80)\n",
    "\n",
    "query_txt = input('1.크롤링할 이미지의 키워드는 무엇입니까?: ')\n",
    "cnt_c = input('2.크롤링 할 건수는 몇건입니까?: ')\n",
    "if cnt_c =='' :\n",
    "        cnt = 5\n",
    "else :\n",
    "    cnt = int(cnt_c)\n",
    "real_cnt = math.ceil(cnt / 20)\n",
    "f_dir=input('3.파일이 저장될 경로만 쓰세요(예: ./py_temp/ ) : ')\n",
    "if f_dir =='' :\n",
    "        f_dir = \"./py_temp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일을 저장할 폴더를 생성합니다\n",
    "n = time.localtime()\n",
    "s = '%04d-%02d-%02d-%02d-%02d-%02d' % (n.tm_year, n.tm_mon, n.tm_mday, n.tm_hour, n.tm_min, n.tm_sec)\n",
    "\n",
    "img_dir = f_dir+s+'-'+query_txt\n",
    "os.makedirs(img_dir)\n",
    "os.chdir(img_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#크롬 드라이버를 사용해서 웹 브라우저를 실행합니다.\n",
    "s_time = time.time( )\n",
    "\n",
    "service = Service(r\"../../116/chromedriver.exe\")\n",
    "options = wd.ChromeOptions()\n",
    "driver = wd.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naver.com')\n",
    "time.sleep(random.randrange(2,5))\n",
    "\n",
    "element = driver.find_element(By.ID,\"query\")\n",
    "element.send_keys(query_txt)\n",
    "element.submit()\n",
    "\n",
    "# driver.find_element(By.ID,\"search-btn\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 링크를 선택합니다\n",
    "driver.find_element(By.LINK_TEXT,\"이미지\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#스크롤 다운 함수 생성 후 화면 이동하기\n",
    "def scroll_down(driver):\n",
    "#     driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")\n",
    "    driver.execute_script(\"window.scrollTo(0,10000);\")\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_down_bottom(self):\n",
    "    \"\"\"A method for scrolling the page.\"\"\"\n",
    "\n",
    "    # Get scroll height.\n",
    "    last_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # Scroll down to the bottom.\n",
    "        self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # Wait to load the page.\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height.\n",
    "        new_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        if new_height == last_height:\n",
    "\n",
    "            break\n",
    "\n",
    "        last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_down_bottom():\n",
    "    \"\"\"A method for scrolling the page.\"\"\"\n",
    "\n",
    "    # Get scroll height.\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # Scroll down to the bottom.\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # Wait to load the page.\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height.\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        if new_height == last_height:\n",
    "\n",
    "            break\n",
    "\n",
    "        last_height = new_height\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium.webdriver import ActionChains # scroll down 사용하기 위하여 선서\n",
    "\n",
    "# # id가 jsOpenView_1 인 element 를 찾음\n",
    "# # stop_tag = driver.find_element(By.ID, 'jsOpenView_1')\n",
    "# stop_tag = driver.find_element(By.ID, 'footer')\n",
    "\n",
    "# # jsOpenView_1 element 까지 스크롤\n",
    "# action = ActionChains(driver)\n",
    "# action.move_to_element(stop_tag).perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "while (i <= real_cnt):\n",
    "    scroll_down(driver) \n",
    "    i += 1\n",
    "\n",
    "#이미지 추출하기  \n",
    "file_no = 1\n",
    "count = 1\n",
    "img_src2=[]\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "img_src = soup.find('div','photo_tile _grid').find_all('div','photo_bx api_ani_send _photoBox')\n",
    "\n",
    "# 아래 코드로 img 태그의 src 속성을 확인할 수 있습니다.\n",
    "#print(img_src[0].find('img')['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_src[0].find('img')['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in img_src :\n",
    "        img_src1= i.find('img')['src']\n",
    "        print(img_src1)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수집 대상 이미지의 URL 정보 추출\n",
    "for i in img_src :\n",
    "        img_src1= i.find('img')['src']\n",
    "        if 'http' in img_src1 :\n",
    "            img_src2.append(img_src1)\n",
    "            \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 이미지 다운로드하여 저장하기\n",
    "for i in range(0,len(img_src2)) :\n",
    "        try :\n",
    "                urllib.request.urlretrieve(img_src2[i],str(file_no)+'.jpg')\n",
    "        except :\n",
    "                continue        \n",
    "            \n",
    "        time.sleep(0.5)      \n",
    "        print(\"%s 번째 이미지 저장중입니다=======\" %file_no)\n",
    "        \n",
    "        file_no += 1  \n",
    "                \n",
    "        if file_no > cnt :\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 이미지 이름에 한글이 들어갈 경우 조치방법\n",
    "for i in range(0,len(img_src2)) :\n",
    "    file_no += 1 \n",
    "    urllib.request.urlretrieve(urllib.parse.quote(img_src2[i].encode('utf8'), '/:'),\\\n",
    "                               str(file_no)+'.jpg')\n",
    "\n",
    "    time.sleep(0.5)      \n",
    "    print(\"%s 번째 이미지 저장중입니다=======\" %file_no)\n",
    "\n",
    "    file_no += 1  \n",
    "\n",
    "    if file_no > cnt :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 요약 정보를 출력합니다                \n",
    "e_time = time.time( )\n",
    "t_time = e_time - s_time\n",
    "\n",
    "store_cnt = file_no -1\n",
    "\n",
    "print(\"=\" *70)\n",
    "print(\"총 소요시간은 %s 초 입니다 \" %round(t_time,1))\n",
    "print(\"총 저장 건수는 %s 건 입니다 \" %store_cnt)\n",
    "print(\"파일 저장 경로: %s 입니다\" %img_dir)\n",
    "print(\"=\" *70)\n",
    "\n",
    "#driver.close( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 2. pixapay 사이트에서 그림 수집하기\n",
    "# Step 1. 필요한 모듈과 라이브러리를 로딩합니다.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver as wd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import urllib.request\n",
    "import urllib\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "#Step 2. 필요한 정보를 입력 받습니다.\n",
    "print(\"=\" *80)\n",
    "print(\" pixabay 사이트에서 이미지를 검색하여 수집하는 크롤러 입니다 \")\n",
    "print(\"=\" *80)\n",
    "\n",
    "query_txt = input('1.크롤링할 이미지의 키워드는 무엇입니까?: ')\n",
    "cnt = int(input('2.크롤링 할 건수는 몇건입니까?: '))\n",
    "real_cnt = math.ceil(cnt / 100) # 실제 크롤링 할 페이지 수\n",
    "f_dir=input('3.파일이 저장될 경로만 쓰세요(예: './py_temp\\\\ ) : ')\n",
    "if f_dir =='' :\n",
    "    f_dir = \"./py_temp\\\\\"\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"요청하신 데이터를 수집 중이오니 잠시만 기다려 주세요~~^^\")\n",
    "\n",
    "#Step 3. 파일을 저장할 폴더를 생성합니다\n",
    "n = time.localtime()\n",
    "s = '%04d-%02d-%02d-%02d-%02d-%02d' % (n.tm_year, n.tm_mon, n.tm_mday, n.tm_hour, n.tm_min, n.tm_sec)\n",
    "\n",
    "img_dir = f_dir+s+'-'+query_txt\n",
    "os.makedirs(img_dir)\n",
    "os.chdir(img_dir)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4. 크롬 드라이버를 사용해서 웹 브라우저를 실행한 후 검색합니다\n",
    "s_time = time.time( )\n",
    "\n",
    "service = Service(r\"../../116/chromedriver.exe\")\n",
    "options = wd.ChromeOptions()\n",
    "driver = wd.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://pixabay.com/ko/')\n",
    "time.sleep(3)\n",
    "\n",
    "driver.maximize_window( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색어 입력 창에 검색어 입력 후 검색 수행\n",
    "element = driver.find_element(By.NAME,'search')\n",
    "element.send_keys(query_txt)\n",
    "element.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 추출하여 저장하기 \n",
    "file_no = 1\n",
    "count = 1\n",
    "img_src2=[]    #이미지 파일의 url 주소 저장용 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스크롤 다운 함수 만들기\n",
    "def scroll_down(driver):\n",
    "    #driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")\n",
    "    driver.execute_script(\"window.scrollBy(0,1000)\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa= soup.find('div','row-masonry search-results')\n",
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(1 , real_cnt+1):  \n",
    "    \n",
    "    for b in range(0,5):\n",
    "        scroll_down(driver)\n",
    "        time.sleep(1)\n",
    "        \n",
    "    # 원본 이미지 url 주소 수집 \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')    \n",
    "#     img_src = soup.find('div','row-masonry search-results').find_all('img')\n",
    "    img_src_all = soup.find_all('a','link--WHWzm')\n",
    "    \n",
    "    \n",
    "    for img_c in img_src_all:\n",
    "        img_src = img_c.find_all('img')\n",
    "\n",
    "        for c in img_src :\n",
    "            img_src1=c['src']\n",
    "\n",
    "            if 'http' in img_src1 :\n",
    "                img_src2.append(img_src1)\n",
    "                print(img_src1)\n",
    "\n",
    "            count += 1  \n",
    "\n",
    "            if count > cnt :\n",
    "                break\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 다운로드하여 저장하기 - 인증 정보 넣지 않을 경우 HTTPError 에러 발생\n",
    "for i in range(0,len(img_src2)) :\n",
    "        #try :\n",
    "        urllib.request.urlretrieve(img_src2[i],str(file_no)+'.jpg')\n",
    "        #except :\n",
    "        #        continue        \n",
    "            \n",
    "        time.sleep(0.5)      \n",
    "        print(\"%s 번째 이미지 저장중입니다=======\" %file_no)\n",
    "        \n",
    "        file_no += 1  \n",
    "                \n",
    "        if file_no > cnt :\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "         \n",
    "    #수집된 url 주소로 이미지 파일 가져와서 저장하기\n",
    "    for e in range(0,len(img_src2)) :\n",
    "\n",
    "        class AppURLopener(urllib.request.FancyURLopener):\n",
    "            version = \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) \\\n",
    "                       Chrome/47.0.2526.69 Safari/537.36\"\n",
    "\n",
    "        urllib.urlopener = AppURLopener()\n",
    "        urllib.urlopener.retrieve(img_src2[e],str(file_no)+'.jpg')\n",
    "\n",
    "        print(\"%s 페이지에서 %s 번째 이미지 저장중입니다=======\" %(a,file_no))\n",
    "\n",
    "        time.sleep(0.5) \n",
    "\n",
    "        if file_no >= cnt :\n",
    "                break\n",
    "\n",
    "        file_no += 1  \n",
    "                \n",
    "#     if a > real_cnt :\n",
    "#         break\n",
    "\n",
    "# Step 6. 요약 정보를 출력합니다                \n",
    "e_time = time.time( )\n",
    "t_time = e_time - s_time\n",
    "\n",
    "print(\"=\" *70)\n",
    "print(\"총 소요시간은 %s 초 입니다 \" %round(t_time,1))\n",
    "print(\"총 저장 건수는 %s 건 입니다 \" %file_no)\n",
    "print(\"파일 저장 경로: %s 입니다\" %img_dir)\n",
    "print(\"=\" *70)\n",
    "\n",
    "driver.close( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://cdn.pixabay.com/photo/2016/11/19/17/33/animal-1840495_640.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url0 = 'https://search.pstatic.net/common/?src=http%3A%2F%…G_k2Su50ZSokIg.JPEG.kh011ylxl%2F921.jpg&type=a340'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode character '\\u2026' in position 28: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl0\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:241\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m url_type, path \u001b[38;5;241m=\u001b[39m _splittype(url)\n\u001b[1;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mclosing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m    242\u001b[0m     headers \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39minfo()\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1348\u001b[0m         \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1349\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m   1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1282\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, url, body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m{}, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   1280\u001b[0m             encode_chunked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1282\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1293\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccept-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m header_names:\n\u001b[0;32m   1291\u001b[0m     skips[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskip_accept_encoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputrequest(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mskips)\n\u001b[0;32m   1295\u001b[0m \u001b[38;5;66;03m# chunked encoding will happen if HTTP/1.1 is used and either\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m \u001b[38;5;66;03m# the caller passes encode_chunked=True or the following\u001b[39;00m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;66;03m# conditions hold:\u001b[39;00m\n\u001b[0;32m   1298\u001b[0m \u001b[38;5;66;03m# 1. content-length has not been explicitly set\u001b[39;00m\n\u001b[0;32m   1299\u001b[0m \u001b[38;5;66;03m# 2. the body is a file or iterable, but not a str or bytes-like\u001b[39;00m\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;66;03m# 3. Transfer-Encoding has NOT been explicitly set by the caller\u001b[39;00m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent-length\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m header_names:\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;66;03m# only chunk body if not explicitly set for backwards\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m     \u001b[38;5;66;03m# compatibility, assuming the client code is already handling the\u001b[39;00m\n\u001b[0;32m   1305\u001b[0m     \u001b[38;5;66;03m# chunking\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1131\u001b[0m, in \u001b[0;36mHTTPConnection.putrequest\u001b[1;34m(self, method, url, skip_host, skip_accept_encoding)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_path(url)\n\u001b[0;32m   1129\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (method, url, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_http_vsn_str)\n\u001b[1;32m-> 1131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_http_vsn \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m11\u001b[39m:\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;66;03m# Issue some standard headers for better HTTP/1.1 compliance\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_host:\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;66;03m# this header is issued *only* for HTTP/1.1\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m         \u001b[38;5;66;03m# connections. more specifically, this means it is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[38;5;66;03m# but the host of the actual URL, not the host of the\u001b[39;00m\n\u001b[0;32m   1149\u001b[0m         \u001b[38;5;66;03m# proxy.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1211\u001b[0m, in \u001b[0;36mHTTPConnection._encode_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, request):\n\u001b[0;32m   1210\u001b[0m     \u001b[38;5;66;03m# ASCII also helps prevent CVE-2019-9740.\u001b[39;00m\n\u001b[1;32m-> 1211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mascii\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character '\\u2026' in position 28: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib\n",
    "urllib.request.urlretrieve(url0,'test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
